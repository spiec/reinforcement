#!/usr/bin/env python
# -*- coding: utf-8 -*-

# ----------------------------------------------------------------------
# Author:   sebastian.piec@
# Modified: 2019, March 10
# ----------------------------------------------------------------------

"""Exploration schemes.
"""

import math
import numpy as np
import sys

# ----------------------------------------------------------------------
class Greedy(object):
    """Always choose action with the maximum expected reward.
    """

    def __init__(self):
        pass

    def __call__(self, actions_vec):
        return np.argmax(actions_vec)

# ----------------------------------------------------------------------
class EpsilonGreedy(object):

    def __init__(self, max_epsilon, min_epsilon, epsilon=None):
        self.max_epsilon = max_epsilon
        self.min_epsilon = min_epsilon

        self.epsilon_function = self.basic_epsilon_scheme if not epsilon else epsilon
        self.epsilon = self.max_epsilon

        self.adjust(0.0)

    def __call__(self, actions_vec):
        if np.random.rand() < self.epsilon:
            return np.random.randint(len(actions_vec))

        return np.argmax(actions_vec)

    def adjust(self, progress):
        """
        Args:
            progress (float), 0.0-1.0 (e.g. episode/n_episodes)
        """
        self.epsilon = self.epsilon_function(progress, self.max_epsilon, self.min_epsilon)

    def basic_epsilon_scheme(self, progress, max_epsilon, min_epsilon):
        return min_epsilon

# ----------------------------------------------------------------------
class Softmax(object):

    def __init__(self):
        pass

    def __call__(self, actions_vec):
        indices = list(range(len(actions_vec)))
        e = np.exp(-actions_vec)
        prob = e / sum(e)

        return np.random.choice(indices, size=1, p=prob)    #actions_vec

    def adjust(self, progress):
        """
        Args:
            progress (float), 0.0-1.0 (e.g. episode/n_episodes)
        """